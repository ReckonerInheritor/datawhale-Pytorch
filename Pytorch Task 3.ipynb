{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch实现Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100,Loss:0.6482,Accuracy：0.66\n",
      "Epoch:200,Loss:0.6159,Accuracy：0.68\n",
      "Epoch:300,Loss:0.5967,Accuracy：0.66\n",
      "Epoch:400,Loss:0.5839,Accuracy：0.67\n",
      "Epoch:500,Loss:0.5746,Accuracy：0.68\n",
      "Epoch:600,Loss:0.5674,Accuracy：0.71\n",
      "Epoch:700,Loss:0.5618,Accuracy：0.72\n",
      "Epoch:800,Loss:0.5571,Accuracy：0.74\n",
      "Epoch:900,Loss:0.5532,Accuracy：0.74\n",
      "Epoch:1000,Loss:0.5498,Accuracy：0.74\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "torch.__version__\n",
    "data=np.loadtxt(\"german.data-numeric\")\n",
    "#归一化处理\n",
    "n,l=data.shape\n",
    "for j in range(l-1):\n",
    "    meanVal=np.mean(data[:,j])\n",
    "    stdVal=np.std(data[:,j])\n",
    "    data[:,j]=(data[:,j]-meanVal)/stdVal\n",
    "    \n",
    "\n",
    "#打乱数据\n",
    "np.random.shuffle(data)\n",
    "\n",
    "train_data=data[:900,:l-1]\n",
    "train_lab=data[:900,l-1]-1\n",
    "test_data=data[900:,:l-1]\n",
    "test_lab=data[900:,l-1]-1\n",
    "\n",
    "class LR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LR,self).__init__()\n",
    "        self.fc=nn.Linear(24,2) # 由于24个维度已经固定了，所以这里写24\n",
    "    def forward(self,x):\n",
    "        out=self.fc(x)\n",
    "        out=torch.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "def test(pred,lab):\n",
    "    t=pred.max(-1)[1]==lab\n",
    "    return torch.mean(t.float())\n",
    "\n",
    "net=LR() \n",
    "criterion=nn.CrossEntropyLoss() # 使用CrossEntropyLoss损失\n",
    "optm=torch.optim.Adam(net.parameters()) # Adam优化\n",
    "epochs=1000 # 训练1000次\n",
    "\n",
    "for i in range(epochs):\n",
    "    # 指定模型为训练模式，计算梯度\n",
    "    net.train()\n",
    "    # 输入值都需要转化成torch的Tensor\n",
    "    x=torch.from_numpy(train_data).float()\n",
    "    y=torch.from_numpy(train_lab).long()\n",
    "    y_hat=net(x)\n",
    "    loss=criterion(y_hat,y) # 计算损失\n",
    "    optm.zero_grad() # 前一步的损失清零\n",
    "    loss.backward() # 反向传播\n",
    "    optm.step() # 优化\n",
    "    if (i+1)%100 ==0 : # 这里我们每100次输出相关的信息\n",
    "        # 指定模型为计算模式\n",
    "        net.eval()\n",
    "        test_in=torch.from_numpy(test_data).float()\n",
    "        test_l=torch.from_numpy(test_lab).long()\n",
    "        test_out=net(test_in)\n",
    "        # 使用我们的测试函数计算准确率\n",
    "        accu=test(test_out,test_l)\n",
    "        print(\"Epoch:{},Loss:{:.4f},Accuracy：{:.2f}\".format(i+1,loss.item(),accu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
